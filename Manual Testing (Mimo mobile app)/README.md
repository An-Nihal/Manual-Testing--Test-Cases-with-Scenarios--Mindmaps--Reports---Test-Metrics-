
# Manual Testing (Mimo mobile application)

Welcome to the Manual Testing (Mimo Mobile App) project repository! This repository contains test artifacts for the manual testing of the Mimo mobile application—an education-based app that allows users to learn coding and programming in various languages such as Python, JavaScript, HTML, and more. The focus of this testing effort has been on the Python Basics module. The repository includes test cases, a test execution report, and test metrics to effectively plan, execute, and track the testing activities for the Mimo mobile app.


## Table of Contents

- Introduction
- Project Overview
- Test Artifacts
- Contributing
- FAQ
## Introduction
Manual testing plays a vital role in ensuring the quality and functionality of the Mimo mobile app—an interactive platform for learning coding and programming. This repository serves as a centralized resource for storing and organizing test artifacts related to the Python Basics module. The test artifacts include test cases, a test execution report, and test metrics.
## Project Overview
The Mimo mobile app is designed to provide an engaging learning experience for users who want to acquire coding and programming skills. With various modules focusing on different programming languages, the app offers interactive lessons, coding exercises, and quizzes to facilitate the learning process. The Python Basics module specifically targets beginners who want to learn the fundamentals of Python programming.
## Test Artifacts
The following test artifacts are included in this project:
- Test Cases
- Test Execution Report
- Test Metrics
## Contributing
Contributions are welcome to enhance the repository with additional test artifacts, such as test cases, test execution reports, or test metrics, related to other modules or languages in the Mimo mobile app. If you have any improvements or suggestions, please feel free to open an issue or submit a pull request. Your contributions will help ensure the overall quality and reliability of the Mimo mobile app.
## FAQ

#### Q1: How can I contribute to this project?

Answer: Contributions are welcome! You can contribute by adding new test cases, scenarios, mindmaps, reports, or test metrics to the respective directories. Simply open an issue or submit a pull request with your proposed changes.

#### Q2:  Can I use the test cases and scenarios provided in this repository for my own projects?

Answer: Absolutely! The test cases and scenarios in this repository are meant to be shared and used as a reference for manual testing projects. Feel free to adapt and utilize them for your own testing efforts.

#### Q3: Is there a specific format or template to follow for test cases?

Answer: While there isn't a strict template to follow, we recommend including the test case ID, description, pre-requisites, test steps, and expected results. You can also add any additional fields that are relevant to your project. Consistency in format across test cases will make it easier to navigate and understand the test suite.

#### Q4: Are all Test processes integrated in one file?

Answer: Yes. In the excel file you can see test cases, scenarios, mindmaps, test report and test metrics. All in one.

